#!/bin/bash

########### EDIT THIS BLOCK WITH SLURM & APPTAINER/SINGULARITY SETTINGS ############
#SBATCH --time=10-00:00:00   
#SBATCH --nodes=1  
#SBATCH --ntasks-per-node=16
#SBATCH --mem=256Gb
#SBATCH --partition=ceres
#SBATCH --account=coffea_pangenome

module load apptainer &> /dev/null || true
#module load singularity &> /dev/null || true
SINGULARITY_TMPDIR=$APPTAINER_TMPDIR
########### EDIT THIS BLOCK WITH SLURM & APPTAINER/SINGULARITY SETTINGS ############

# Default values
SAMPLE=""
MAP_FILE=""
RUNTIME=""
t=16
MEM=256

# Display help message
function show_help {
    echo "Usage: puzzle_quality [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --sample SAMPLE       Sample name (required)"
    echo "  --map FILE       Path to .tsv/.csv map file (required)"
    echo "  --threads t           Number of threads (optional; default 16)"
    echo "  --mem MEM             Memory allocation (Gb, optional; default 256)"
    echo "  --help                Show this help message and exit"
    exit 0
}

# Parse command-line arguments
while [[ "$#" -gt 0 ]]; do
    case "$1" in
        -h|--help) show_help ;;  
        -s|--sample) SAMPLE="$2"; shift ;;
        -m|--map) MAP_FILE="$2"; shift ;;
        -t|--threads) t="$2"; shift ;;
        --mem) MEM="$2"; shift ;;
        *) echo "Unknown option: $1"; exit 1 ;;
    esac
    shift
done

# Validate required arguments
if [ -z "$SAMPLE" ]; then
    echo "Error: --sample argument is required."
    exit 1
fi

if [ -z "$MAP_FILE" ]; then
    echo "Error: --map argument is required."
    exit 1
fi

# Read CSV line matching sample and assign fields
IFS=$'\t,' read -r _ RUNTIME SIF_PATH OUTDIR ASSEMBLY HIFI BLOB_DB BUSCO_LINEAGE BUSCO_DB < <(
    awk -F'[\t,]' -v sample="$SAMPLE" '$1 == sample {print $0}' "${MAP_FILE}"
)

if [ "$RUNTIME" = "conda" ]; then
    PQ=""  # No runtime needed for Conda
else
    PQ="${RUNTIME} exec ${SIF_PATH}"
fi

cat << "EOF"

==============================================================
__________ ____ _______________________.____     ___________   
\______   \    |   \____    /\____    /|    |    \_   _____/   
 |     ___/    |   / /     /   /     / |    |     |    __)_    
 |    |   |    |  / /     /_  /     /_ |    |___  |        \   
 |____|   |______/ /_______ \/_______ \|_______ \/_______  /   
                           \/        \/        \/        \/    
________   ____ ___  _____  .____    .___________________.___. 
\_____  \ |    |   \/  _  \ |    |   |   \__    ___/\__  |   | 
 /  / \  \|    |   /  /_\  \|    |   |   | |    |    /   |   | 
/   \_/.  \    |  /    |    \    |___|   | |    |    \____   | 
\_____\ \_/______/\____|__  /_______ \___| |____|    / ______| 
       \__>               \/        \/               \/        
==============================================================

EOF

echo -e "=======================================================================\nParameters for sample: ${SAMPLE} \nCONTAINER: ${SIF_PATH} \nOUTDIR: ${OUTDIR} \nASSEMBLY: ${ASSEMBLY} \nHIFI: ${HIFI} \nBlobtools database: ${BLOB_DB} \nBUSCO lineage: ${BUSCO_LINEAGE} \nBUSCO database: ${BUSCO_DB} \nRUNTIME: ${RUNTIME}\n=======================================================================\n"

set -euo pipefail
${PQ} busco --version > /dev/null 2>&1 || { -e "\e[40m~~~~ busco not found, is runtime set and container exists? ~~~~\e[0m"; exit 1; } 
${PQ} blobtools --version > /dev/null 2>&1 || { -e "\e[40m~~~~ blobtools not found, is runtime set and container exists? ~~~~\e[0m"; exit 1; } 
set +e +u +o pipefail 

mkdir -p ${OUTDIR}/work/${SAMPLE}

##### BUSCO: detect conserved genes, first download database #####


###### BUSCO ######
if [ -s "${OUTDIR}/${SAMPLE}.busco.txt" ]; then 
	echo -e "\e[42m~~~~ Skipping BUSCO for ${SAMPLE}: ${OUTDIR}/${SAMPLE}.busco.txt exists ~~~~\e[0m"
elif [ ! -s "${ASSEMBLY}" ]; then
	echo -e "\e[41m~~~~ Skipping BUSCO for ${SAMPLE}, missing input: ${ASSEMBLY} ~~~~\e[0m"
elif [[ ! -s "${BUSCO_LINEAGE}" || "${BUSCO_DB}" == "NA" ]]; then
	echo -e "\e[41m~~~~ Skipping BUSCO for ${SAMPLE}, not requested ~~~~\e[0m"
else 
	echo -e "\e[43m~~~~ Running BUSCO for ${SAMPLE} using lineage: ${BUSCO_LINEAGE} ~~~~\e[0m"

    if [ ! -d "${BUSCO_DB}/lineages/${BUSCO_LINEAGE}" ]; then
        echo -e "\e[43m~~~~ Downloading BUSCO Lineage database: ${BUSCO_LINEAGE} ~~~~\e[0m"
        ${PQ} busco --download ${BUSCO_LINEAGE} --download_path ${BUSCO_DB} > ${OUTDIR}/work/${SAMPLE}.busco_download.log 2>&1
    else
        echo -e "\e[42m~~~~ BUSCO lineage dataset already exists, skipping ~~~~\e[0m"
    fi

    cd ${OUTDIR}/work/${SAMPLE}

    ${PQ} busco -i ${ASSEMBLY} \
        -l ${BUSCO_DB}/lineages/${BUSCO_LINEAGE} \
        -m genome \
        -c 16 \
        -o ${SAMPLE} \
        -f > ${OUTDIR}/work/${SAMPLE}.busco.log 2>&1

    mv ${SAMPLE}/short_summary.specific.${BUSCO_LINEAGE}.${SAMPLE}.txt ${OUTDIR}/${SAMPLE}.busco.txt
fi

##### Map HiFi Reads back to Assembly ##### 
if [ -s "${OUTDIR}/${SAMPLE}.hifi_coverage.txt" ]; then 
	echo -e "\e[42m~~~~ Skipping HiFi coverage for ${SAMPLE}: ${OUTDIR}/${SAMPLE}.hifi_coverage.txt exists ~~~~\e[0m"
elif [ ! -s "${ASSEMBLY}" ]; then
	echo -e "\e[41m~~~~ Skipping HiFi alignment for ${SAMPLE}, missing input: ${ASSEMBLY} ~~~~\e[0m"
elif [ ! -s "${HIFI}" ]; then
	echo -e "\e[41m~~~~ Skipping HiFi alignment for ${SAMPLE}, missing input: ${HIFI} ~~~~\e[0m"
elif [ "$HIFI" = "NA" ]; then
	echo -e "\e[41m~~~~ Skipping HiFi alignment for ${SAMPLE}, not desired ~~~~\e[0m"
else 
    cd ${OUTDIR}/work/${SAMPLE}

	# Alignment 
	if [ ! -s "${OUTDIR}/work/${SAMPLE}/${SAMPLE}.hifi.bam" ]; then
        echo -e "\e[43m~~~~ Starting HiFi Alignment for ${SAMPLE} ~~~~\e[0m"
        { ${PQ} minimap2 -t ${t} -ax map-hifi \
			${ASSEMBLY} ${HIFI} 2> ${SAMPLE}.hifi.minimap.log | \
			${PQ} samtools sort --threads ${t} -o ${SAMPLE}.hifi.bam; } > ${OUTDIR}/work/${SAMPLE}.hifi.alignment.log 2>&1
        ${PQ} samtools index --threads ${t} ${SAMPLE}.hifi.bam
		${PQ} mosdepth --by 250000 --mapq 30 --no-per-base ${SAMPLE}.hifi ${SAMPLE}.hifi.bam
        zcat ${SAMPLE}.hifi.regions.bed.gz | awk -v s=${SAMPLE} '{OFS="\t"}{print $0, s}' > ${OUTDIR}/${SAMPLE}.hifi_coverage.txt

	else
		echo -e "\e[42m~~~~ Skipping HiFi Alignment for ${SAMPLE}, ${OUTDIR}/work/${SAMPLE}/${SAMPLE}.hifi.bam exists ~~~~\e[0m"
	fi 
fi # exit HiFi check

##### YAK k-mer QV ##### 
if [ -s "${OUTDIR}/${SAMPLE}.qv.txt" ]; then 
	echo -e "\e[42m~~~~ Skipping YAK k-mer QV for ${SAMPLE}: ${OUTDIR}/${SAMPLE}.qv.txt ~~~~\e[0m"
elif [ ! -s "${ASSEMBLY}" ]; then
	echo -e "\e[41m~~~~ Skipping YAK k-mer QV for ${SAMPLE}, missing input: ${ASSEMBLY} ~~~~\e[0m"
elif [ ! -s "${HIFI}" ]; then
	echo -e "\e[41m~~~~ Skipping YAK k-mer QV stats for ${SAMPLE}, missing input: ${HIFI} ~~~~\e[0m"
elif [ "$HIFI" = "NA" ]; then
	echo -e "\e[41m~~~~ Skipping YAK k-mer QV for ${SAMPLE}, not desired ~~~~\e[0m"
else 
	echo -e "\e[43m~~~~ Running YAK on ${SAMPLE} ~~~~\e[0m"
    cd ${OUTDIR}/work/${SAMPLE}

    ${PQ} yak count -b37 -t ${t} -o ${SAMPLE}.ccs.yak ${HIFI} > yak.count.log 2>&1
    ${PQ} yak qv -t ${t} -p -K3.2g -l100k ${SAMPLE}.ccs.yak ${ASSEMBLY} > ${SAMPLE}-sr.qv.txt 2> yak.qv.log
    cp ${SAMPLE}-sr.qv.txt ${OUTDIR}/${SAMPLE}.qv.txt

fi

##### Blobtools contamination search ##### 
if [ -s "${OUTDIR}/${SAMPLE}.blob.txt" ]; then 
	echo -e "\e[42m~~~~ Skipping blobtools for ${SAMPLE}: ${OUTDIR}/${SAMPLE}.stats.txt exists ~~~~\e[0m"
elif [ ! -s "${ASSEMBLY}" ]; then
	echo -e "\e[41m~~~~ Skipping blobtools for ${SAMPLE}, missing input: ${ASSEMBLY} ~~~~\e[0m"
elif [ ! -s "${HIFI}" ]; then
	echo -e "\e[41m~~~~ Skipping blobtools for ${SAMPLE}, missing input: ${HIFI} ~~~~\e[0m"
elif [ "${BLOB_DB}" = "NA" ]; then
	echo -e "\e[41m~~~~ Skipping blobtools for ${SAMPLE}, not desired ~~~~\e[0m"
else 
	echo -e "\e[43m~~~~ Running blobtools on ${SAMPLE} ~~~~\e[0m"

    # Download Refseq Taxdump
    cd ${BLOB_DB}
    mkdir -p data
    if [ ! -s "${BLOB_DB}/data/nodes.dmp" ]; then
        echo -e "\e[43m~~~~ Grabbing NCBI taxdump files ~~~~\e[0m"
        wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz -P data/ > ncbi_dump.wget.log 2>&1
        tar zxf data/taxdump.tar.gz -C data/ nodes.dmp names.dmp > ncbi_dump.tar.log 2>&1
        ${PQ} blobtools nodesdb --nodes data/nodes.dmp --names data/names.dmp > ncbi_dump.nodedump.log 2>&1

	else
		echo -e "\e[42m~~~~ Skipping NCBI taxdump, ${BLOB_DB}/data/nodes.dmp exists ~~~~\e[0m"
	fi 

    # Download refseq nt databases (MASSIVE!) 
    mkdir -p nt
    if [ ! -s "${BLOB_DB}/nt/core_nt.ndb" ]; then
        echo -e "\e[43m~~~~ Downloading RefSeq nt database.... will take hours ~~~~\e[0m"
        curl -s ftp://ftp.ncbi.nlm.nih.gov/blast/db/ | grep "nt.[0-9][0-9].tar.gz" | awk '{print "ftp://ftp.ncbi.nlm.nih.gov/blast/db/"$NF}' | xargs -n 1 wget -P nt/
        for file in nt/*.tar.gz; do 
            tar xf $file -C nt && rm $file; 
        done
	else
		echo -e "\e[42m~~~~ Skipping RefSeq nt download, ${BLOB_DB}/nr/core_nt.ndb exists ~~~~\e[0m"
	fi 

    # # Grab refseq uniprot proteomes (MASSIVE!)
    # mkdir -p uniprot
    # if [ ! -s "${BLOB_DB}/uniprot/reference_proteomes.dmnd" ]; then
    #     echo -e "\e[43m~~~~ Downloading uniprot reference proteome database.... will take hours ~~~~\e[0m"

    #     wget -q -O uniprot/reference_proteomes.tar.gz \
    #     ftp.ebi.ac.uk/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/$(curl \
    #         -vs ftp.ebi.ac.uk/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/ 2>&1 | \
    #         awk '/tar.gz/ {print $9}')
    #     cd uniprot
    #     tar xf reference_proteomes.tar.gz

    #     touch reference_proteomes.fasta.gz
    #     find . -mindepth 2 | grep "fasta.gz" | grep -v 'DNA' | grep -v 'additional' | xargs cat >> reference_proteomes.fasta.gz

    #     echo -e "accession\taccession.version\ttaxid\tgi" > reference_proteomes.taxid_map
    #     zcat */*/*.idmapping.gz | grep "NCBI_TaxID" | awk '{print $1 "\t" $1 "\t" $3 "\t" 0}' >> reference_proteomes.taxid_map

    #     echo -e "\e[43m~~~~ Creating diamond uniprot reference proteome database.... ~~~~\e[0m"
    #     ${PQ} diamond makedb -p 16 --in reference_proteomes.fasta.gz --taxonmap reference_proteomes.taxid_map --taxonnodes ../taxdump/nodes.dmp -d reference_proteomes.dmnd
    #     cd -
	# else
	# 	echo -e "\e[42m~~~~ Skipping diamond uniprot databases, ${BLOB_DB}/uniprot/reference_proteomes.dmnd exists ~~~~\e[0m"
	# fi 

    cd ${BLOB_DB}
    if [ ! -s "${BLOB_DB}/uniprot/reference_proteomes.dmnd" ]; then
        echo -e "\e[43m~~~~ Blasting reference against databases ~~~~\e[0m"
        ${PQ} blastn -db nt/nt_core \
            -query ${ASSEMBLY} \
            -outfmt "6 qseqid staxids bitscore std" \
            -max_target_seqs 10 \
            -max_hsps 1 \
            -evalue 1e-25 \
            -num_threads 16 \
            -out ${SAMPLE}_blast.out
	else
		echo -e "\e[42m~~~~ Skipping blast, ${BLOB_DB}/${SAMPLE}_blast.out exists ~~~~\e[0m"
	fi 

    if [ ! -s "${BLOB_DB}/data/nodes.dmp" ]; then
        echo -e "\e[43m~~~~ Creating blobplot for ${SAMPLE} ~~~~\e[0m"
        ${PQ} blobtools create -i ${ASSEMBLY} -b ${OUTDIR}/work/${SAMPLE}/${SAMPLE}.hifi.bam --db data/nodes.db --nodes ${BLOB_DB}/data/nodes.dmp --names ${BLOB_DB}/data/names.dmp -t example/blast.out -o example/test && \
            ${PQ} blobtools view -i example/test.blobDB.json && \
            ${PQ} blobtools plot -i example/test.blobDB.json

	else
		echo -e "\e[42m~~~~ Skipping NCBI taxdump, ${BLOB_DB}/data/nodes.dmp exists ~~~~\e[0m"
	fi 
fi

##### Basic Assembly Stats ##### 
if [ -s "${OUTDIR}/${SAMPLE}.stats.txt" ]; then 
	echo -e "\e[42m~~~~ Skipping final assembly stats for ${SAMPLE}: ${OUTDIR}/${SAMPLE}.stats.txt exists ~~~~\e[0m"
elif [ ! -s "${ASSEMBLY}" ]; then
	echo -e "\e[41m~~~~ Skipping final assembly stats for ${SAMPLE}, missing input: ${ASSEMBLY} ~~~~\e[0m"
elif [ ! -s "${OUTDIR}/${SAMPLE}.busco.txt" ]; then
	echo -e "\e[41m~~~~ Skipping final assembly stats for ${SAMPLE}, missing input: ${OUTDIR}/${SAMPLE}.busco.txt ~~~~\e[0m"
else 
	echo -e "\e[43m~~~~ Summarizing Assembly for ${SAMPLE} ~~~~\e[0m"
    # Get metrics for final assembly
    cd ${OUTDIR}/work/${SAMPLE}

    FINAL_STATS=$(${PQ} assembly_stats ${ASSEMBLY})
    SIZE=$(echo "$FINAL_STATS" | tr ':' '\n' | grep -A 1 'total_bps' | tail -n1 | sed 's/,//g')
    SEQS=$(echo "$FINAL_STATS" | tr ':' '\n' | grep -A 1 'sequence' | tail -n1 | sed 's/,//g')
    CTGS=$(echo "$FINAL_STATS" | tr ':' '\n' | grep -A 1 'sequence' | head -n2 | tail -n1 | sed 's/,//g')
    SCAF_N50=$(echo "$FINAL_STATS" | tr ':' '\n' | grep -A 1 'N50' | tail -n1 | sed 's/,//g')
    CONT_N50=$(echo "$FINAL_STATS" | tr ':' '\n' | grep -A 1 'N50' | head -n2 | tail -n1 | sed 's/,//g')
    GAPS=$((CTGS - SEQS))

    # What percentage of the assembly is in named chromosomes
    ${PQ} samtools faidx ${ASSEMBLY}
    egrep 'chr|Chr' ${ASSEMBLY}.fai | awk '$1 !~ /A/' | cut -f1 > ${SAMPLE}.chrs
    ${PQ} samtools faidx ${ASSEMBLY} -r ${SAMPLE}.chrs > ${SAMPLE}.chr.fa
    CHR_STATS=$(${PQ} assembly_stats ${SAMPLE}.chr.fa)
    CHR_SIZE=$(echo "$CHR_STATS" | tr ':' '\n' | grep -A 1 'total_bps' | tail -n1 | sed 's/,//g')
    CHR_PROP=$(${PQ} perl -e "print sprintf('%.4f', $CHR_SIZE / $SIZE)")
    NUM_CHRS=$(cat ${SAMPLE}.chrs | wc -l)

    HEADER="Sample\tSizeBP\tWithinChrsBP\tPropWithinChrs\tChrs\tSequences\tContigs\tGaps\tContigN50\tScafN50"
    VALUES="${SAMPLE}\t$SIZE\t$CHR_SIZE\t$CHR_PROP\t$NUM_CHRS\t$SEQS\t$CTGS\t$GAPS\t$CONT_N50\t$SCAF_N50"

    # Add BUSCO metrics **only if BUSCO_LINEAGE is not "NA"**
    if [ "$BUSCO_LINEAGE" != "NA" ]; then
        # Parse BUSCO results
        BUSCO_COMPLETE=$(grep "C:" ${OUTDIR}/${SAMPLE}.busco.txt | cut -d'[' -f1 | cut -d':' -f2 | cut -d'%' -f1)
        BUSCO_SINGLE=$(grep "C:" ${OUTDIR}/${SAMPLE}.busco.txt | cut -d'[' -f2 | cut -d'%' -f1 | sed 's/S://g')

        HEADER+="\tBUSCO_Complete\tBUSCO_singlecopy"
        VALUES+="\t$BUSCO_COMPLETE\t$BUSCO_SINGLE"
    fi

    # Add QV metrics **only if HIFI is not "NA"**
    if [ "$HIFI" != "NA" ]; then
        # Parse QV results
        YAK_CV=$(awk '$1 == "CV"' ${OUTDIR}/${SAMPLE}.qv.txt | cut -f2)
        YAK_QV=$(awk '$1 == "QV"' ${OUTDIR}/${SAMPLE}.qv.txt | cut -f2)

        HEADER+="\tYAK_CV\tYAK_QV"
        VALUES+="\t$YAK_CV\t$YAK_QV"
    fi

    # Write to summary file
    echo -e "$HEADER" > ${OUTDIR}/${SAMPLE}.summary.txt
    echo -e "$VALUES" >> ${OUTDIR}/${SAMPLE}.summary.txt

fi # exit assembly stat check