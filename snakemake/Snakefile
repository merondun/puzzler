# Snakefile

def get_haps_for_sample(sample):
    return list(range(1, config["samples"][sample]["ploidy"] + 1))

rule all:
    input:
        expand(
            config["workdir"] + "/{sample}/HiCHiFi/02_PurgeDups/hap{hap}/purged.fa",
            sample=list(config["samples"].keys()),
            hap=get_haps_for_sample(list(config["samples"].keys())[0])
        ),
        expand(
            config["workdir"] + "/{sample}/HiCHiFi/03_HapHiC/hap{hap}.purged.haphic.fa",
            sample=list(config["samples"].keys()),
            hap=get_haps_for_sample(list(config["samples"].keys())[0])
        ),
        expand(
            config["workdir"] + "/{sample}/HiCHiFi/04_PurgeDups/hap{hap}/purged.fa",
            sample=list(config["samples"].keys()),
            hap=get_haps_for_sample(list(config["samples"].keys())[0])
        ),
        expand(
            config["workdir"] + "/Haplotype_Assemblies/{sample}.hap{hap}.purged.haphic.purged.ragtag.fa",
            sample=list(config["samples"].keys()),
            hap=get_haps_for_sample(list(config["samples"].keys())[0])
        )

# Primary assembly
rule hifiasm_hic:
    input:
        hifi = lambda wildcards: config["samples"][wildcards.sample]["hifi"],
        hic_r1 = lambda wildcards: config["samples"][wildcards.sample]["hic_r1"],
        hic_r2 = lambda wildcards: config["samples"][wildcards.sample]["hic_r2"]
    output:
        hap_files = expand(config["workdir"] + "/{{sample}}/HiCHiFi/{{sample}}.hic.hap{hap}.p_ctg.gfa", 
            hap=[i for i in range(1, config["samples"][list(config["samples"].keys())[0]]["ploidy"] + 1)]),
        complete = touch(config["workdir"] + "/{sample}/HiCHiFi/hifiasm_complete.txt")
    params:
        ploidy = lambda wildcards: config["samples"][wildcards.sample]["ploidy"],
        outprefix = config["workdir"] + "/{sample}/HiCHiFi/{sample}"
    threads: 64
    resources:
        mem_mb=500000  # 500GB in MB
    singularity: config["container"]
    shell:
        """
        echo "~~~~ Starting HiFiasm-HiC Assembly for {wildcards.sample} ~~~~"
        hifiasm --n-hap {params.ploidy} -s 0.9 -t {threads} \
            --h1 {input.hic_r1} --h2 {input.hic_r2} \
            -o {params.outprefix} {input.hifi}
        echo "~~~~ HiFiasm-HiC Assembly Complete ~~~~"
        """
        
rule purge_dups:
    input:
        gfa = config["workdir"] + "/{sample}/HiCHiFi/{sample}.hic.hap{hap}.p_ctg.gfa",
        # Make sure hifiasm_hic completed
        hifiasm_done = config["workdir"] + "/{sample}/HiCHiFi/hifiasm_complete.txt"
    output:
        purged = config["workdir"] + "/{sample}/HiCHiFi/02_PurgeDups/hap{hap}/purged.fa"
    threads: 64
    resources:
        mem_mb=500000  # 500GB in MB
    singularity: config["container"]
    shell:
        """
        echo "~~~~ Starting Purge_Dups for {wildcards.sample} haplotype {wildcards.hap} ~~~~"
        mkdir -p $(dirname {output.purged})
        cd $(dirname {output.purged})
        
        gfatools gfa2fa {input.gfa} > {wildcards.sample}.hap{wildcards.hap}.fa
        split_fa {wildcards.sample}.hap{wildcards.hap}.fa > asm.split
        minimap2 -t {threads} -xasm5 -DP asm.split asm.split | gzip -c > asm.split.self.paf.gz
        purge_dups -M1000 -E1000 asm.split.self.paf.gz > dups.bed
        get_seqs dups.bed {wildcards.sample}.hap{wildcards.hap}.fa
        
        echo "~~~~ Purge_Dups Complete for haplotype {wildcards.hap} ~~~~"
        """

rule haphic_phase:
    input:
        purged_haps = expand(config["workdir"] + "/{{sample}}/HiCHiFi/02_PurgeDups/hap{hap}/purged.fa",
                           hap=get_haps_for_sample(list(config["samples"].keys())[0])),
        hic_r1 = lambda wildcards: config["samples"][wildcards.sample]["hic_r1"],
        hic_r2 = lambda wildcards: config["samples"][wildcards.sample]["hic_r2"],
        reference = lambda wildcards: config["samples"][wildcards.sample]["reference"]
    output:
        scaffolds = expand(config["workdir"] + "/{{sample}}/HiCHiFi/03_HapHiC/hap{hap}.purged.haphic.fa",
                         hap=get_haps_for_sample(list(config["samples"].keys())[0])),
        completed = touch(config["workdir"] + "/{sample}/HiCHiFi/03_HapHiC/haphic_complete.txt")
    params:
        nchrs = lambda wildcards: config["samples"][wildcards.sample]["nchrs"],
        ploidy = lambda wildcards: config["samples"][wildcards.sample]["ploidy"],
        work_dir = config["workdir"] + "/{sample}/HiCHiFi/03_HapHiC"
    threads: 64
    resources:
        mem_mb=500000
    singularity: config["container"]
    shell:
        """
        echo "~~~~ Scaffolding with HapHiC {wildcards.sample} ~~~~"
        # Create and enter working directory
        mkdir -p {params.work_dir}
        cd {params.work_dir}

        # Merge haplotypes
        cat ../02_PurgeDups/hap*/purged.fa > {wildcards.sample}.hic.allhap.fa
        
        # Index merged assembly
        bwa index {wildcards.sample}.hic.allhap.fa

        # Align Hi-C reads
        bwa mem -5SP -t {threads} {wildcards.sample}.hic.allhap.fa {input.hic_r1} {input.hic_r2} | \
            samblaster | samtools view - -@ {threads} -S -h -b -F 3340 -o HiC.bam

        # Filter alignments
        filter_bam HiC.bam 30 --nm 3 --threads {threads} --remove-dup | \
            samtools view - -b -@ {threads} -o HiC.filtered.bam

        # Process each haplotype
        for HAP in $(seq 1 {params.ploidy}); do
            mkdir -p hap${{HAP}}
            cd hap${{HAP}}

            samtools faidx ../../02_PurgeDups/hap${{HAP}}/purged.fa
            awk '{{OFS="\t"}}{{print $1, "0",$2}}' ../../02_PurgeDups/hap${{HAP}}/purged.fa.fai > hap${{HAP}}.bed

            samtools view -b -h -L hap${{HAP}}.bed ../HiC.filtered.bam > HiC.filtered.hap${{HAP}}.bam

            rm -rf 01* 02* 03* 04*
            
            # Run HapHiC pipeline
            haphic pipeline ../../02_PurgeDups/hap${{HAP}}/purged.fa \
                HiC.filtered.hap${{HAP}}.bam \
                {params.nchrs} \
                --correct_nrounds 2 \
                --threads {threads} \
                --processes {threads} \
                --max_inflation 20.0 \
                --remove_allelic_links {params.ploidy}
            
            cp 04.build/scaffolds.fa ../hap${{HAP}}.purged.haphic.fa

        done

        echo "~~~~ Scaffolding with HapHiC {wildcards.sample} complete ~~~~"
        """

rule repurge_hic:
    input:
        purgehic = config["workdir"] + "/{sample}/HiCHiFi/03_HapHiC/hap{hap}.purged.haphic.fa",
        # Make sure hifiasm_hic completed
        haphic_done = config["workdir"] + "/{sample}/HiCHiFi/03_HapHiC/haphic_complete.txt"
    output:
        purgedhic = config["workdir"] + "/{sample}/HiCHiFi/04_PurgeDups/hap{hap}/purged.fa"
    threads: 64
    resources:
        mem_mb=500000  # 500GB in MB
    singularity: config["container"]
    shell:
        """
        echo "~~~~ Starting Second Round Purge_Dups for {wildcards.sample} haplotype {wildcards.hap} ~~~~"
        mkdir -p $(dirname {output.purgedhic})
        cd $(dirname {output.purgedhic})
        
        split_fa {input.purgehic} > asm.split
        minimap2 -t {threads} -xasm5 -DP asm.split asm.split | gzip -c > asm.split.self.paf.gz
        purge_dups -M1000 -E1000 asm.split.self.paf.gz > dups.bed
        get_seqs dups.bed {input.purgehic}
        
        echo "~~~~ Second Purge_Dups Complete for haplotype {wildcards.hap} ~~~~"
        """

rule ragtag:
    input:
        purgedhic = config["workdir"] + "/{sample}/HiCHiFi/04_PurgeDups/hap{hap}/purged.fa",
        reference = lambda wildcards: config["samples"][wildcards.sample]["reference"]
    output:
        final_assembly = config["workdir"] + "/Haplotype_Assemblies/{sample}.hap{hap}.purged.haphic.purged.ragtag.fa"
    params:
        work_dir = config["workdir"] + "/{sample}/HiCHiFi/05_RagTag/hap{hap}"
    threads: 64
    resources:
        mem_mb=500000  # 500GB in MB
    singularity: config["container"]
    shell:
        """
        echo "~~~~ Starting RagTag Scaffolding for {wildcards.sample} haplotype {wildcards.hap} ~~~~"
        mkdir -p {params.work_dir}
        cd {params.work_dir}
        
        ragtag.py scaffold {input.reference} {input.purgedhic} -o hap{wildcards.hap} --aligner minimap2 -t {threads}
        cp hap{wildcards.hap}/ragtag.scaffold.fasta hap{wildcards.hap}.purged.haphic.purged.ragtag.fa
        
        mkdir -p $(dirname {output.final_assembly[0]})
        cp hap{wildcards.hap}.purged.haphic.purged.ragtag.fa $(dirname {output.final_assembly[0]})/{wildcards.sample}.hap{wildcards.hap}.purged.haphic.purged.ragtag.fa

        echo "~~~~ Ragtag Scaffolding Complete for {wildcards.sample} and haplotype {wildcards.hap} ~~~~"
        """